{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation (CV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Hold out Cross Validation\n",
    "* k-fold Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A test set should still be held out for final evaluation, but the validation set is no longer needed when doing CV. \n",
    "\n",
    "In the basic approach, called k-fold CV, the training set is split into k smaller sets. The following procedure is followed for each of the k “folds”:\n",
    "* A model is trained using k-1 of the folds as training data;\n",
    "* the resulting model is validated on the remaining part of the data (i.e., it is used as a test set to compute a performance measure such as accuracy).\n",
    "\n",
    "The performance measure reported by k-fold cross-validation is then the average of the values computed in the loop. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Holdout Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Split initial dataset into a separate training and test dataset\n",
    "* Training dataset - model training\n",
    "* Test dataset - estimate its generalisation performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/holdout method.png' width=50%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A variation is to split the training set to two :- training set and validation set\n",
    "\n",
    "Training set:- For fitting different models\n",
    "\n",
    "Validation set :- For tuning and comparing different parameter settings to further improve the performance for making predictions on unseen data. And finally for model selection.\n",
    "\n",
    "This process is called model selection. We want to select the optimal values of tuning parameters (also called hyperparameters). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/holdout method w validation.png' width=50%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-fold Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Randomly split the training dataset into k folds without replacement.\n",
    "\n",
    "* k — 1 folds are used for the model training.\n",
    "\n",
    "* The one fold is used for performance evaluation. \n",
    "\n",
    "This procedure is repeated k times. \n",
    "\n",
    "Final outcomes:- k models and performance estimates.\n",
    "\n",
    "* calculate the average performance of the models based on the different, independent folds to obtain a performance estimate that is less sensitive to the sub-partitioning of the training data compared to the holdout method. \n",
    "\n",
    "* k-fold cross-validation is used for model tuning. Finding the optimal hyperparameter values that yields a satisfying generalization performance.\n",
    "\n",
    "* Once we have found satisfactory hyperparameter values, we can retrain the model on the complete training set and obtain a final performance estimate using the independent test set. The rationale behind fitting a model to the whole training dataset after k-fold cross-validation is that providing more training samples to a learning algorithm usually results in a more accurate and robust model.\n",
    "\n",
    "\n",
    "* Common k is 10\n",
    "\n",
    "* For relatively small training sets, increase the number of folds. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/cross validation.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified k-fold cross-validation\n",
    "\n",
    "* variation of k-fold\n",
    "* Can yield better bias and variance estimates, especially in cases of unequal class proportions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Illustration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation: evaluating estimator performance\n",
    "\n",
    "Adapted from [scikit learn](Cross-validation: evaluating estimator performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**overfitting**:\n",
    "* It is a mistake to expose your machine learning algorithm to both training and testing data\n",
    "* This will lead to overfitting\n",
    "* It will give a high score \n",
    "* Utterly useless for unseen data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**:\n",
    "\n",
    "* Hyperparameters for estimators, such as the `C` for SVM, must be set manually\n",
    "* There is still a risk of overfitting on the test set because one can continually tweek the parameters\n",
    "* To avoid this, another part of the dataset should be held out as “validation set”\n",
    "    1. Training proceeds on the training set\n",
    "    2. Evaluation is done on the validation set\n",
    "    3. Final evaluation can be done on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This raised another issues as we have drastically reduced the number of samples which can be used for learning the model\n",
    "* To get around this, we utilise a procedure called cross-validation (CV). \n",
    "* A test set should still be held out for final evaluation\n",
    "* The validation set is no longer needed when doing CV. \n",
    "* In k-fold CV, the training set is split into k smaller sets\n",
    "* The following procedure is followed for each of the k “folds”:\n",
    "    * A model is trained using k-1 of the folds as training data\n",
    "    * The resulting model is validated on the remaining part of the data (i.e., it is used as a test set to compute a performance measure such as accuracy).\n",
    "    * The performance measure reported by k-fold cross-validation is then the average of the values. \n",
    "* Can be computationally expensive\n",
    "* Does not waste too much data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Best Practice**:\n",
    "* Hold out part of the available data as a **test set** `X_test`, `y_test`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In **scikit-learn** a random split into training and test sets can be quickly computed with the `train_test_split` helper function. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((506, 13), (506,))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "\n",
    "boston = datasets.load_boston()\n",
    "boston.data.shape, boston.target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now quickly sample a training set while holding out 40% of the data for testing (evaluating) our regressor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66725541579404235"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    boston.data, boston.target, test_size=0.4, random_state=0)\n",
    "\n",
    "X_train.shape, y_train.shape\n",
    "\n",
    "X_test.shape, y_test.shape\n",
    "\n",
    "\n",
    "regression = svm.SVR(kernel='linear', C=1).fit(X_train, y_train)\n",
    "regression.score(X_test, y_test)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing cross-validated metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.77328953,  0.72833447,  0.53795481,  0.15209389,  0.07729196])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "regression = svm.SVR(kernel='linear', C=1)\n",
    "scores = cross_val_score(regression, boston.data, boston.target, cv=5)\n",
    "scores        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean score and the 95% confidence interval of the score estimate are hence given by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.45 (+/- 0.58)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the score computed at each CV iteration is the score method of the estimator. It is possible to change this by using the scoring parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -7.82949025, -24.73154773, -37.00390719, -74.37141515, -24.53325372])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "scores = cross_val_score(\n",
    "    regression, boston.data, boston.target, cv=5, scoring='neg_mean_squared_error')\n",
    "scores "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [The scoring parameter: defining model evaluation rules](http://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter) for details. In the case of the Iris dataset, the samples are balanced across target classes hence the accuracy and the F1-score are almost equal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the `cv` argument is an integer, `cross_val_score` uses the `KFold` or `StratifiedKFold` strategies by default, the latter being used if the estimator derives from ClassifierMixin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`KFold` divides all the samples in k groups of samples, called folds (if k = n, this is equivalent to the Leave One Out strategy), of equal sizes (if possible). \n",
    "\n",
    "The prediction function is learned using k - 1 folds, and the fold left out is used for test.\n",
    "\n",
    "Example of 2-fold cross-validation on a dataset with 4 samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3] [0 1]\n",
      "[0 1] [2 3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "X = [\"a\", \"b\", \"c\", \"d\"]\n",
    "kf = KFold(n_splits=2)\n",
    "for train, test in kf.split(X):\n",
    "    print(\"%s %s\" % (train, test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified k-fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StratifiedKFold is a variation of k-fold which returns stratified folds\n",
    "\n",
    "Each set contains approximately the same percentage of samples of each target class as the complete set.\n",
    "\n",
    "Example of stratified 3-fold cross-validation on a dataset with 10 samples from two slightly unbalanced classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 6 7 8 9] [0 1 4 5]\n",
      "[0 1 3 4 5 8 9] [2 6 7]\n",
      "[0 1 2 4 5 6 7] [3 8 9]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "X = np.ones(10)\n",
    "y = [0, 0, 0, 0, 1, 1, 1, 1, 1, 1]\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "for train, test in skf.split(X, y):\n",
    "    print(\"%s %s\" % (train, test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.391\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.pipeline import make_pipeline\n",
    "#pipe_lr = make_pipeline(StandardScaler(),\n",
    "#                        PCA(n_components=2),\n",
    "#                        LogisticRegression(random_state=1))\n",
    "pipe_svm = make_pipeline(StandardScaler(),\n",
    "                        PCA(n_components=2),\n",
    "                        svm.SVR(kernel='linear', C=1))\n",
    "pipe_svm.fit(X_train, y_train)\n",
    "y_pred = pipe_svm.predict(X_test)\n",
    "print('Test Accuracy: %.3f' % pipe_svm.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy scores: [ 0.63971176  0.43579197  0.46977821  0.25027246  0.5124364   0.26221374\n",
      "  0.30877195  0.54528563  0.37810066  0.47313549]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(estimator=pipe_svm,\n",
    "                         X=X_train,\n",
    "                         y=y_train,\n",
    "                         cv=10,\n",
    "                         n_jobs=1)\n",
    "print('CV accuracy scores: %s' % scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy: 0.428 +/- 0.121\n"
     ]
    }
   ],
   "source": [
    "print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores),\n",
    "                                      np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
